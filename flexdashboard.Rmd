---
title: "Newspaper Content Analysis"
author: "Elise Hachfeld and Theresa Worden"
output: 
  flexdashboard::flex_dashboard:
    #vertical_layout: scroll
    theme:
      version: 4
      bootswatch: yeti
runtime: shiny
---
```{r global, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(DT)
library(igraph)
```

```{r}
download.file("https://raw.githubusercontent.com/elisefeld/loc_ph_data/main/Data/raw_data.rds",
  destfile = "raw_data.rds")

data_clean <- readRDS("raw_data.rds") |>
  select(index,
         date,
         title,
         partof_title,
         description,
         url,
         image_url,
         language,
         location_state,
         location_county, location_city,
         contributor,
         publication_frequency,
         subject,
         subject_ethnicity) |>
  mutate(across(where(is.list) & !all_of("subject"),
                ~ sapply(.x, function(val) paste(val, collapse = ', ')))) |>
  
  mutate(language = str_remove(language, "[, ]?english[, ]?"),
         language = str_remove(language, ","),
         language = str_trim(language)) |>
  
  rename(newspaper_title = partof_title,
         text_data = description,
         state = location_state,
         city = location_city,
         other_language = language) |>
  
  mutate(across(everything(), ~ ifelse(. == "", NA, .))) |>
  mutate(across(everything(), ~ ifelse(. == "NULL", NA, .))) |>
  mutate(as_date = ymd(date))

bing_sentiments <- get_sentiments("bing")
smart_stopwords <- get_stopwords(source = "smart")
```

# About

## Column {data-width="500"}

### Background

By [Elise Hachfeld](https://github.com/elisefeld) and [Theresa Worden](https://github.com/wordentheresa0)

The way people consume media has changed drastically since 1941, but has it's content? We are interested in how major historical events affect the sentiment of people reflected in the media. To investigate this, we looked at the text of newspapers before and after the bombing of Pearl Harbor on December 7th, 1941.
We sourced our data

from the Library of Congress [Chronicling America](https://www.loc.gov/collections/chronicling-america/about-this-collection/) project, which contains historical American newspapers from 17?? to 1963.

The data was accessed through the Chronicling America API using the [httr2](https://httr2.r-lib.org) and [jsonlite](https://jeroen.r-universe.dev/jsonlite) packages.

View some more Pearl Harbor front pages [here](https://www.nypl.org/blog/2017/12/07/pearl-harbor-front-page).

## Column {data-width="500"}

```{r picture, echo = F, out.width = '100%'}
knitr::include_graphics("images/pearl_harbor_front_page.png")
```


# Common Words
## Column {data-width="500"}
```{r}
words <- data_clean |>
  mutate(row_id = row_number()) |>
  unnest_tokens(word, text_data, token = "words") |>
  filter(str_detect(word, "[a-z]"))  #filter out hebrew characters and numbers

words_clean <- words |>
  anti_join(smart_stopwords) |>
  count(word, sort = TRUE)

words_clean |>
  head(1000) |>
  DT::datatable(options = list(bPaginate = TRUE)) #Not sure why this isn't showing on the site
```

## Column {data-width="500"}
```{r}
ngram <- data_clean |>
  unnest_tokens(bigram, text_data, token = "ngrams", n = 2) |>
  filter(bigram != "NA")

ngram_filter <- ngram |>
  separate(bigram, c("word1", "word2"), sep = " ") |>
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word) |>
  count(word1, word2, sort = TRUE)

ngram_filter_graph <- ngram_filter |>
  filter(n > 2) |>
  graph_from_data_frame()

#ggraph(ngram_filter_graph, layout = "fr") +
#  geom_edge_link() +
#  geom_node_point() +
#  geom_node_text(aes(label = name), vjust = 1, hjust = 1)
```


# Section

## Column {data-width="400"}

### Box 1

```{r eruptions, echo=FALSE}

```

### Parameters

```{r}
#Add code for adjusting data here

```

## Column {data-width="300"}

### Box 3

Talk about the graph here.

# Sentiment Analysis

## Row {.tabset .tabset-fade}

### Box 1
```{r, echo=FALSE}
bing <- words |>
  inner_join(bing_sentiments, by = "word")

bing_by_page <- bing |>
  mutate(sentiment_value = ifelse(sentiment == "positive", 1, -1)) |>
  group_by(index) |>
  summarize(avg_sentiment = mean(sentiment_value, na.rm = TRUE)) |>
  arrange(index)
```

```{r}
bing |>
  count(index, sentiment) |>
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |>
  mutate(sentiment = positive - negative) |>
  ggplot(aes(x = index, y = sentiment, fill = sentiment > 0)) +
  geom_col(show.legend = FALSE) +
  theme_minimal() +
  labs(
    x = "index",
    y = "average",
    title = "average sentiment by description"
  )
```

### Box 2

```{r, echo=FALSE}
date_bing <- bing |>
  group_by(index, date) |>
  mutate(sentiment_value = ifelse(sentiment == "positive", 1, -1)) |>
  summarize(avg_sentiment = mean(sentiment_value, na.rm = TRUE), .groups = "drop") |>
  arrange(date)

date_summary <- date_bing |>
  group_by(date) |>
  summarize(avg_sentiment = mean(avg_sentiment, na.rm = TRUE), .groups = "drop")

ggplot(date_summary, aes(x = as.Date(date), y = avg_sentiment, fill = avg_sentiment > 0)) +
  geom_col(show.legend = FALSE) +
  theme_minimal() +
  labs(
    x = "date",
    y = "average sentiment",
    title = "average sentiment by date"
  ) +
  scale_x_date(date_breaks = "1 month", date_labels = "%b %d")

print(date_summary$date)
str(bing)
str(date_bing)
head(date_summary)
```

## Row

### Box 3

Talk about the graph here.

### Parameters

```{r}
#Add code for adjusting data here

```

# Section 3

# Section 4
